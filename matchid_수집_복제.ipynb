{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f22c3e28-b0ac-4750-b44c-3140edf9ef0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime, timezone, timedelta\n",
    "import csv\n",
    "import os\n",
    "import requests\n",
    "import json\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0930c5b2-fac7-41d8-8160-b9c75e71edd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# kr_high = pd.read_csv('data/01_puuids/kr_puuids_high_tiers.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "773bc67f-ef4b-42e7-9374-8e5dfa24f78a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# os.mkdir('data/02_match-v5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4bd223cf-ee5b-427b-b327-9a4a81277373",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1736373600\n"
     ]
    }
   ],
   "source": [
    "kst = timezone(timedelta(hours=9))\n",
    "startTime = datetime(2025, 1, 9, 7, 0, 0, tzinfo=kst)\n",
    "print(int(startTime.timestamp()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fa8651e1-19a4-4e15-93d5-b65df9def4f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2025 1ì›” 9ì¼ 07:00 (25.1.1íŒ¨ì¹˜ ì ìš© ì‹œê°„ KST)\n",
    "startTime_unix = int(startTime.timestamp())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1f10afc1-d7c7-4791-9de9-0c7afec4f1ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def unix_conv(unix_time):\n",
    "    dt = datetime.datetime.utcfromtimestamp(unix_time)\n",
    "    dt = dt.strftime('%Y-%m-%d %H:%M:%S')\n",
    "    return dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "821a2b4e-ba71-42e3-9f2f-688c1fc4a92e",
   "metadata": {},
   "outputs": [],
   "source": [
    "API_KEY=\"RGAPI-ec13736b-acd7-4c71-883c-b94e97c40c13\"\n",
    "HEADERS = {\"X-Riot-Token\": API_KEY}\n",
    "\n",
    "REGION_MAPPING = {\n",
    "    'KR': 'asia', 'JP1': 'asia',\n",
    "    'BR1': 'americas', 'NA1': 'americas', 'LA1': 'americas', 'LA2': 'americas',\n",
    "    'EUN1': 'europe', 'EUW1': 'europe', 'TR1': 'europe', 'RU': 'europe', 'ME1': 'europe',\n",
    "    'OC1': 'sea', 'SG2': 'sea', 'TW2': 'sea', 'VN2': 'sea'\n",
    "}\n",
    "\n",
    "OUTPUT_FILE = \"data/02_match-v5/collected_match_ids.csv\"\n",
    "PROGRESS_FILE = \"data/02_match-v5/processed_puuids.txt\"  # ìˆ˜ì§‘ ì™„ë£Œëœ ìœ ì € ì €ì¥ìš©\n",
    "SAVE_INTERVAL = 10\n",
    "\n",
    "def get_matches_for_one_user(puuid, platform, total_count=1000):\n",
    "    routing = REGION_MAPPING.get(platform.upper(), 'asia')\n",
    "    url = f\"https://{routing}.api.riotgames.com/lol/match/v5/matches/by-puuid/{puuid}/ids\"\n",
    "    \n",
    "    user_match_ids = []\n",
    "    for start_index in range(0, total_count, 100):\n",
    "        params = {\n",
    "            \"api_key\" : API_KEY,\n",
    "            # \"queue\": 420,\n",
    "            \"startTime\" : startTime_unix,\n",
    "            \"start\": start_index, \n",
    "            \"count\": 100}\n",
    "        try:\n",
    "            response = requests.get(url, headers=HEADERS, params=params)\n",
    "            if response.status_code == 200:\n",
    "                fetched_ids = response.json()\n",
    "                user_match_ids.extend(fetched_ids)\n",
    "                if len(fetched_ids) < 100: break # ë” ì´ìƒ ë°ì´í„° ì—†ìŒ\n",
    "            elif response.status_code == 429:\n",
    "                print(\"!! Rate Limit! 10ì´ˆ ëŒ€ê¸°...\")\n",
    "                time.sleep(10)\n",
    "                continue # í˜„ì¬ êµ¬ê°„ ë‹¤ì‹œ ì‹œë„\n",
    "            else:\n",
    "                break\n",
    "            time.sleep(0.05) # Personal Key ì†ë„ ì¤€ìˆ˜\n",
    "        except Exception as e:\n",
    "            print(f\"ì˜¤ë¥˜: {e}\")\n",
    "            break\n",
    "    return user_match_ids\n",
    "\n",
    "def save_to_csv(match_id_set, file_name):\n",
    "    \"\"\"\n",
    "    ìˆ˜ì§‘ëœ ë§¤ì¹˜ ID ì„¸íŠ¸ë¥¼ CSVì— ì €ì¥ (ì¤‘ë³µ ì œê±° í¬í•¨)\n",
    "    \"\"\"\n",
    "    new_df = pd.DataFrame(list(match_id_set), columns=['match_id'])\n",
    "    \n",
    "    # íŒŒì¼ì´ ì—†ìœ¼ë©´ ìƒˆë¡œ ë§Œë“¤ê³ (header í¬í•¨), ìˆìœ¼ë©´ ì´ì–´ ì“°ê¸°(header ì œì™¸)\n",
    "    if not os.path.exists(file_name):\n",
    "        new_df.to_csv(file_name, index=False, mode='w', encoding='utf-8')\n",
    "    else:\n",
    "        new_df.to_csv(file_name, index=False, mode='a', header=False, encoding='utf-8')\n",
    "    \n",
    "    print(f\"--- [ì¤‘ê°„ ì €ì¥ ì™„ë£Œ] {len(new_df)}ê°œì˜ ìƒˆë¡œìš´ ë§¤ì¹˜ ID ì €ì¥ë¨ ---\")\n",
    "\n",
    "def collect_with_checkpoints(df_dict):\n",
    "    current_session_matches = set() # í˜„ì¬ ì„¸ì…˜ì—ì„œì˜ ì¤‘ë³µ ë°©ì§€ìš©\n",
    "    \n",
    "    for platform, df in df_dict.items():\n",
    "        print(f\"\\nğŸš€ {platform} ì§€ì—­ ìˆ˜ì§‘ ì‹œì‘...\")\n",
    "        \n",
    "        for idx, puuid in enumerate(df['puuid']):\n",
    "            m_ids = get_matches_for_one_user(puuid, platform)\n",
    "            current_session_matches.update(m_ids)\n",
    "            \n",
    "            # ì¤‘ê°„ ì €ì¥ ë¡œì§: SAVE_INTERVAL(10ëª…) ë§ˆë‹¤ ì‹¤í–‰\n",
    "            if (idx + 1) % SAVE_INTERVAL == 0:\n",
    "                print(f\"[{idx+1}/{len(df)}] ì§„í–‰ ì¤‘...\", end=' ')\n",
    "                save_to_csv(current_session_matches, OUTPUT_FILE)\n",
    "                # ì €ì¥ í›„ ì„¸ì…˜ì„ ë¹„ì›Œì£¼ë©´ ë©”ëª¨ë¦¬ ë¶€ë‹´ì´ ì¤„ì–´ë“­ë‹ˆë‹¤.\n",
    "                current_session_matches.clear() \n",
    "\n",
    "        # ì§€ì—­ í•˜ë‚˜ê°€ ëë‚˜ë©´ ë‚¨ì€ ë°ì´í„° ì €ì¥\n",
    "        if current_session_matches:\n",
    "            save_to_csv(current_session_matches, OUTPUT_FILE)\n",
    "            current_session_matches.clear()\n",
    "\n",
    "    # ë§ˆì§€ë§‰ìœ¼ë¡œ ì „ì²´ íŒŒì¼ì—ì„œ í˜¹ì‹œ ëª¨ë¥¼ ì¤‘ë³µ ì œê±°\n",
    "    final_cleanup(OUTPUT_FILE)\n",
    "\n",
    "def final_cleanup(file_name):\n",
    "    print(\"\\nğŸ§¹ ì „ì²´ ë°ì´í„° ì¤‘ë³µ ì œê±° ì‘ì—… ì‹œì‘...\")\n",
    "    df = pd.read_csv(file_name)\n",
    "    before_count = len(df)\n",
    "    df.drop_duplicates(subset=['match_id'], inplace=True)\n",
    "    df.to_csv(file_name, index=False)\n",
    "    print(f\"âœ… ìµœì¢… ì™„ë£Œ! ({before_count} -> {len(df)}ê°œ)\")\n",
    "\n",
    "# ì‹¤í–‰\n",
    "# collect_with_checkpoints(df_dict)\n",
    "\n",
    "def load_processed_puuids():\n",
    "    \"\"\"ì´ë¯¸ ìˆ˜ì§‘ ì™„ë£Œëœ ìœ ì € ëª©ë¡ì„ ë¶ˆëŸ¬ì˜µë‹ˆë‹¤.\"\"\"\n",
    "    if os.path.exists(PROGRESS_FILE):\n",
    "        with open(PROGRESS_FILE, 'r') as f:\n",
    "            # í•œ ì¤„ì”© ì½ì–´ì„œ ì„¸íŠ¸ì— ì €ì¥ (ì¤‘ë³µ ì œê±° ë° ë¹ ë¥¸ ê²€ìƒ‰ìš©)\n",
    "            return set(line.strip() for line in f)\n",
    "    return set()\n",
    "\n",
    "def save_progress(puuid_list):\n",
    "    \"\"\"ìˆ˜ì§‘ ì™„ë£Œëœ ìœ ì € ëª©ë¡ì„ íŒŒì¼ì— ì¶”ê°€í•©ë‹ˆë‹¤.\"\"\"\n",
    "    with open(PROGRESS_FILE, 'a') as f:\n",
    "        for puuid in puuid_list:\n",
    "            f.write(f\"{puuid}\\n\")\n",
    "\n",
    "def collect_with_resume(df_dict):\n",
    "    # 1. ì‘ì—… ì™„ë£Œ ëª…ë‹¨ ë¡œë“œ\n",
    "    processed_puuids = load_processed_puuids()\n",
    "    print(f\"ğŸ“Š ê¸°ì¡´ ì‘ì—… ê¸°ë¡ í™•ì¸: {len(processed_puuids)}ëª…ì˜ ìœ ì €ëŠ” ì´ë¯¸ ìˆ˜ì§‘ë˜ì—ˆìŠµë‹ˆë‹¤.\")\n",
    "\n",
    "    current_session_matches = set()\n",
    "    newly_processed_this_session = [] # ì´ë²ˆ ì„¸ì…˜ì—ì„œ ìƒˆë¡œ ì™„ë£Œí•œ ìœ ì €ë“¤\n",
    "\n",
    "    for platform, df in df_dict.items():\n",
    "        print(f\"\\nğŸš€ {platform} ì§€ì—­ ìˆ˜ì§‘ ì‹œì‘...\")\n",
    "        \n",
    "        for idx, puuid in enumerate(df['puuid']):\n",
    "            # 2. ê±´ë„ˆë›°ê¸° ë¡œì§\n",
    "            if puuid in processed_puuids:\n",
    "                continue \n",
    "\n",
    "            # 3. ë°ì´í„° ìˆ˜ì§‘\n",
    "            m_ids = get_matches_for_one_user(puuid, platform)\n",
    "            current_session_matches.update(m_ids)\n",
    "            newly_processed_this_session.append(puuid)\n",
    "            \n",
    "            # 4. ì¤‘ê°„ ì €ì¥ (SAVE_INTERVAL ë§ˆë‹¤)\n",
    "            if len(newly_processed_this_session) >= SAVE_INTERVAL:\n",
    "                print(f\"[{idx+1}/{len(df)}] ì €ì¥ ì¤‘...\", end=' ')\n",
    "                save_to_csv(current_session_matches, OUTPUT_FILE)\n",
    "                save_progress(newly_processed_this_session) # ìœ ì € ëª…ë‹¨ë„ ì €ì¥\n",
    "                \n",
    "                # ë©”ëª¨ë¦¬ ë¹„ìš°ê¸°\n",
    "                current_session_matches.clear()\n",
    "                processed_puuids.update(newly_processed_this_session)\n",
    "                newly_processed_this_session = []\n",
    "\n",
    "        # ì§€ì—­ ì¢…ë£Œ í›„ ë‚¨ì€ ë°ì´í„° ì²˜ë¦¬\n",
    "        if newly_processed_this_session:\n",
    "            save_to_csv(current_session_matches, OUTPUT_FILE)\n",
    "            save_progress(newly_processed_this_session)\n",
    "            current_session_matches.clear()\n",
    "            newly_processed_this_session = []\n",
    "\n",
    "    print(\"\\nâœ¨ ëª¨ë“  ì§€ì—­ ìˆ˜ì§‘ í”„ë¡œì„¸ìŠ¤ê°€ ì¢…ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "537ad0a5-f419-461d-9b12-401a097d5326",
   "metadata": {},
   "source": [
    "## EXE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bff50435-1e99-41cf-a7a7-3dd933f66fc2",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'kr_puuids_high_tiers.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m kr_high=\u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mkr_puuids_high_tiers.csv\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      2\u001b[39m br1_high=pd.read_csv(\u001b[33m'\u001b[39m\u001b[33m br1_puuids_high_tiers.csv\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m      3\u001b[39m eun1_high=pd.read_csv(\u001b[33m'\u001b[39m\u001b[33m eun1_puuids_high_tiers.csv\u001b[39m\u001b[33m'\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\user\\Desktop\\auto_program\\.venv\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1026\u001b[39m, in \u001b[36mread_csv\u001b[39m\u001b[34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[39m\n\u001b[32m   1013\u001b[39m kwds_defaults = _refine_defaults_read(\n\u001b[32m   1014\u001b[39m     dialect,\n\u001b[32m   1015\u001b[39m     delimiter,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1022\u001b[39m     dtype_backend=dtype_backend,\n\u001b[32m   1023\u001b[39m )\n\u001b[32m   1024\u001b[39m kwds.update(kwds_defaults)\n\u001b[32m-> \u001b[39m\u001b[32m1026\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\user\\Desktop\\auto_program\\.venv\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:620\u001b[39m, in \u001b[36m_read\u001b[39m\u001b[34m(filepath_or_buffer, kwds)\u001b[39m\n\u001b[32m    617\u001b[39m _validate_names(kwds.get(\u001b[33m\"\u001b[39m\u001b[33mnames\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[32m    619\u001b[39m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m620\u001b[39m parser = \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    622\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[32m    623\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\user\\Desktop\\auto_program\\.venv\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1620\u001b[39m, in \u001b[36mTextFileReader.__init__\u001b[39m\u001b[34m(self, f, engine, **kwds)\u001b[39m\n\u001b[32m   1617\u001b[39m     \u001b[38;5;28mself\u001b[39m.options[\u001b[33m\"\u001b[39m\u001b[33mhas_index_names\u001b[39m\u001b[33m\"\u001b[39m] = kwds[\u001b[33m\"\u001b[39m\u001b[33mhas_index_names\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m   1619\u001b[39m \u001b[38;5;28mself\u001b[39m.handles: IOHandles | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1620\u001b[39m \u001b[38;5;28mself\u001b[39m._engine = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\user\\Desktop\\auto_program\\.venv\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1880\u001b[39m, in \u001b[36mTextFileReader._make_engine\u001b[39m\u001b[34m(self, f, engine)\u001b[39m\n\u001b[32m   1878\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[32m   1879\u001b[39m         mode += \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1880\u001b[39m \u001b[38;5;28mself\u001b[39m.handles = \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1881\u001b[39m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1882\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1883\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mencoding\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1884\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcompression\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1885\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmemory_map\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1886\u001b[39m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[43m=\u001b[49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1887\u001b[39m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mencoding_errors\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstrict\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1888\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstorage_options\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1889\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1890\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m.handles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1891\u001b[39m f = \u001b[38;5;28mself\u001b[39m.handles.handle\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\user\\Desktop\\auto_program\\.venv\\Lib\\site-packages\\pandas\\io\\common.py:873\u001b[39m, in \u001b[36mget_handle\u001b[39m\u001b[34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[39m\n\u001b[32m    868\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[32m    869\u001b[39m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[32m    870\u001b[39m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[32m    871\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m ioargs.encoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs.mode:\n\u001b[32m    872\u001b[39m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m873\u001b[39m         handle = \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[32m    874\u001b[39m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    875\u001b[39m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    876\u001b[39m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[43mioargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    877\u001b[39m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    878\u001b[39m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    879\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    880\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    881\u001b[39m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[32m    882\u001b[39m         handle = \u001b[38;5;28mopen\u001b[39m(handle, ioargs.mode)\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: 'kr_puuids_high_tiers.csv'"
     ]
    }
   ],
   "source": [
    "kr_high=pd.read_csv('kr_puuids_high_tiers.csv')\n",
    "br1_high=pd.read_csv(' br1_puuids_high_tiers.csv')\n",
    "eun1_high=pd.read_csv(' eun1_puuids_high_tiers.csv')\n",
    "euw1_high=pd.read_csv(' euw1_puuids_high_tiers.csv')\n",
    "jp1_high=pd.read_csv(' jp1_puuids_high_tiers.csv')\n",
    "la1_high=pd.read_csv(' la1_puuids_high_tiers.csv')\n",
    "la2_high=pd.read_csv(' la2_puuids_high_tiers.csv')\n",
    "me1_high=pd.read_csv(' me1_puuids_high_tiers.csv')\n",
    "na1_high=pd.read_csv(' na1_puuids_high_tiers.csv')\n",
    "oc1_high=pd.read_csv(' oc1_puuids_high_tiers.csv')\n",
    "ru_high=pd.read_csv(' ru_puuids_high_tiers.csv')\n",
    "sg2_high=pd.read_csv(' sg2_puuids_high_tiers.csv')\n",
    "tr1_high=pd.read_csv(' tr1_puuids_high_tiers.csv')\n",
    "tw2_high=pd.read_csv(' tw2_puuids_high_tiers.csv')\n",
    "vn2_high=pd.read_csv(' vn2_puuids_high_tiers.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "450b96fd-5639-42df-a553-5227b3e49977",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'kr_high' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m df_dict_high_tiers = {\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mKR\u001b[39m\u001b[33m\"\u001b[39m: \u001b[43mkr_high\u001b[49m,\n\u001b[32m      3\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mBR1\u001b[39m\u001b[33m\"\u001b[39m: br1_high,\n\u001b[32m      4\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mEUN1\u001b[39m\u001b[33m\"\u001b[39m: eun1_high,\n\u001b[32m      5\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mEUW1\u001b[39m\u001b[33m\"\u001b[39m: euw1_high,\n\u001b[32m      6\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mJP1\u001b[39m\u001b[33m\"\u001b[39m: jp1_high,\n\u001b[32m      7\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mLA1\u001b[39m\u001b[33m\"\u001b[39m: la1_high,\n\u001b[32m      8\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mLA2\u001b[39m\u001b[33m\"\u001b[39m: la2_high,\n\u001b[32m      9\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mME1\u001b[39m\u001b[33m\"\u001b[39m: me1_high,\n\u001b[32m     10\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mNA1\u001b[39m\u001b[33m\"\u001b[39m: na1_high,\n\u001b[32m     11\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mOC1\u001b[39m\u001b[33m\"\u001b[39m: oc1_high,\n\u001b[32m     12\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mRU\u001b[39m\u001b[33m\"\u001b[39m: ru_high,\n\u001b[32m     13\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mSG2\u001b[39m\u001b[33m\"\u001b[39m: sg2_high,\n\u001b[32m     14\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mTR1\u001b[39m\u001b[33m\"\u001b[39m: tr1_high,\n\u001b[32m     15\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mTW2\u001b[39m\u001b[33m\"\u001b[39m: tw2_high,\n\u001b[32m     16\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mVN2\u001b[39m\u001b[33m\"\u001b[39m: vn2_high\n\u001b[32m     17\u001b[39m }\n",
      "\u001b[31mNameError\u001b[39m: name 'kr_high' is not defined"
     ]
    }
   ],
   "source": [
    "df_dict_high_tiers = {\n",
    "    \"KR\": kr_high,\n",
    "    \"BR1\": br1_high,\n",
    "    \"EUN1\": eun1_high,\n",
    "    \"EUW1\": euw1_high,\n",
    "    \"JP1\": jp1_high,\n",
    "    \"LA1\": la1_high,\n",
    "    \"LA2\": la2_high,\n",
    "    \"ME1\": me1_high,\n",
    "    \"NA1\": na1_high,\n",
    "    \"OC1\": oc1_high,\n",
    "    \"RU\": ru_high,\n",
    "    \"SG2\": sg2_high,\n",
    "    \"TR1\": tr1_high,\n",
    "    \"TW2\": tw2_high,\n",
    "    \"VN2\": vn2_high\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc86c9c5-942c-4814-9035-56ab96bee619",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“Š ê¸°ì¡´ ì‘ì—… ê¸°ë¡ í™•ì¸: 5100ëª…ì˜ ìœ ì €ëŠ” ì´ë¯¸ ìˆ˜ì§‘ë˜ì—ˆìŠµë‹ˆë‹¤.\n",
      "\n",
      "ğŸš€ KR ì§€ì—­ ìˆ˜ì§‘ ì‹œì‘...\n",
      "[5110/11000] ì €ì¥ ì¤‘... --- [ì¤‘ê°„ ì €ì¥ ì™„ë£Œ] 7231ê°œì˜ ìƒˆë¡œìš´ ë§¤ì¹˜ ID ì €ì¥ë¨ ---\n",
      "!! Rate Limit! 10ì´ˆ ëŒ€ê¸°...\n",
      "!! Rate Limit! 10ì´ˆ ëŒ€ê¸°...\n",
      "!! Rate Limit! 10ì´ˆ ëŒ€ê¸°...\n",
      "!! Rate Limit! 10ì´ˆ ëŒ€ê¸°...\n",
      "!! Rate Limit! 10ì´ˆ ëŒ€ê¸°...\n",
      "!! Rate Limit! 10ì´ˆ ëŒ€ê¸°...\n",
      "!! Rate Limit! 10ì´ˆ ëŒ€ê¸°...\n"
     ]
    }
   ],
   "source": [
    "collect_with_resume(df_dict_high_tiers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a93e47f5-2834-4cd5-b92b-010be6e9a333",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import time\n",
    "import os\n",
    "\n",
    "# 1. ì„¤ì • (ê¸°ì¡´ ë…¸íŠ¸ë¶ ë³€ìˆ˜ í™œìš©)\n",
    "# API_KEYëŠ” ê¸°ì¡´ ì…€ì— ì…ë ¥ëœ ê²ƒì„ ê·¸ëŒ€ë¡œ ì‚¬ìš©í•˜ê±°ë‚˜ ì•„ë˜ì— ë‹¤ì‹œ ì…ë ¥í•˜ì„¸ìš”.\n",
    "# API_KEY = \"ë‚´_API_KEY\" \n",
    "HEADERS = {\"X-Riot-Token\": API_KEY}\n",
    "\n",
    "# ì„œë²„ë³„ ë§¤ì¹˜ ì§€ì—­(Regional) ë¼ìš°íŒ… ì„¤ì •\n",
    "# BR1, LA1 -> AMERICAS / TR1 -> EUROPE / VN2 -> ASIA\n",
    "routing_map = {\n",
    "    \"br1\": \"americas\",\n",
    "    \"la1\": \"americas\",\n",
    "    \"tr1\": \"europe\",\n",
    "    \"vn2\": \"asia\"\n",
    "}\n",
    "\n",
    "platforms = ['br1', 'la1', 'tr1', 'vn2']\n",
    "\n",
    "for pf in platforms:\n",
    "    print(f\"\\n>>> [{pf.upper()}] ë§¤ì¹˜ ID ìˆ˜ì§‘ ì‹œì‘\")\n",
    "    \n",
    "    # (1) ìƒ˜í”Œë§ëœ PUUID íŒŒì¼ ì½ê¸°\n",
    "    file_path = f\"{pf}_combined_high_sampled.csv\"\n",
    "    if not os.path.exists(file_path):\n",
    "        print(f\"âŒ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {file_path}\")\n",
    "        continue\n",
    "        \n",
    "    df_sample = pd.read_csv(file_path)\n",
    "    puuids = df_sample['puuid'].unique()\n",
    "    \n",
    "    region = routing_map[pf]\n",
    "    all_match_ids = set() # ì¤‘ë³µ ë°©ì§€ë¥¼ ìœ„í•´ set ì‚¬ìš©\n",
    "\n",
    "    # (2) ê° PUUIDë³„ë¡œ ìµœê·¼ 20ê²Œì„ ë§¤ì¹˜ ID í˜¸ì¶œ\n",
    "    for i, puuid in enumerate(puuids):\n",
    "        # 2ë¶„ë‹¹ 100íšŒ(ê°œë°œí‚¤ ê¸°ì¤€) ì œí•œì„ ê³ ë ¤í•œ ì†ë„ ì¡°ì ˆ\n",
    "        if i % 10 == 0 and i > 0:\n",
    "            print(f\"  - ì§„í–‰ë¥ : {i}/{len(puuids)} ëª… ì™„ë£Œ...\")\n",
    "            \n",
    "        url = f\"https://{region}.api.riotgames.com/lol/match/v5/matches/by-puuid/{puuid}/ids?start=0&count=20\"\n",
    "        \n",
    "        try:\n",
    "            response = requests.get(url, headers=HEADERS)\n",
    "            \n",
    "            if response.status_code == 200:\n",
    "                match_ids = response.json()\n",
    "                all_match_ids.update(match_ids)\n",
    "            elif response.status_code == 429:\n",
    "                print(\"!! Rate Limit ë°œìƒ! 10ì´ˆ ëŒ€ê¸°...\")\n",
    "                time.sleep(10)\n",
    "            else:\n",
    "                print(f\"!! ì—ëŸ¬ ë°œìƒ ({response.status_code})\")\n",
    "                \n",
    "            time.sleep(0.05) # ë¯¸ì„¸í•œ ì§€ì—°ìœ¼ë¡œ ì•ˆì •ì„± í™•ë³´\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"!! ì—°ê²° ì˜¤ë¥˜: {e}\")\n",
    "\n",
    "    # (3) ê²°ê³¼ ì €ì¥\n",
    "    match_df = pd.DataFrame(list(all_match_ids), columns=['matchId'])\n",
    "    output_path = f\"{pf}_sampled_match_ids.csv\"\n",
    "    match_df.to_csv(output_path, index=False, encoding='utf-8-sig')\n",
    "    \n",
    "    print(f\"âœ… [{pf.upper()}] ìˆ˜ì§‘ ì™„ë£Œ: ì´ {len(match_df)}ê°œì˜ ê³ ìœ  ë§¤ì¹˜ ID ì €ì¥\")\n",
    "\n",
    "print(\"\\nâœ¨ ëª¨ë“  ì„œë²„ì˜ ë§¤ì¹˜ ID ìˆ˜ì§‘ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03e99f90",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
